import torch
from langchain_chroma import Chroma
from loguru import logger
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
import json
import os

from app.config import settings


class ChromaVectorStore:
    def __init__(self):
        """
        Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ð¿ÑƒÑÑ‚Ð¾Ð¹ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ð° Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð².
        Ð¡Ð¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ñ Ð±Ð°Ð·Ð¾Ð¹ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð±ÑƒÐ´ÐµÑ‚ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ Ð¿Ð¾Ð·Ð¶Ðµ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð¼ÐµÑ‚Ð¾Ð´Ð° init().
        """
        self._store: Chroma | None = None
        self.embeddings = None

    async def init(self):
        """
        ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð»Ñ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ñ Ð±Ð°Ð·Ð¾Ð¹ Ð´Ð°Ð½Ð½Ñ‹Ñ… Chroma.
        Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ embeddings Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸Ð· Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐº, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ CUDA ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾.
        """
        logger.info("ðŸ§  Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ChromaVectorStore...")
        try:
            device = "cuda" if torch.cuda.is_available() else "cpu"
            logger.info(f"ðŸš€ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ Ð´Ð»Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²: {device}")

            self.embeddings = HuggingFaceEmbeddings(
                model_name=settings.LM_MODEL_NAME,
                model_kwargs={"device": device},
                encode_kwargs={"normalize_embeddings": True},
            )

            self._store = Chroma(
                persist_directory=settings.STORAGE_CHROMA_PATH,
                embedding_function=self.embeddings,
                collection_name=settings.STORAGE_COLLECTION_NAME,
            )

            logger.success(
                f"âœ… ChromaVectorStore ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½ Ðº ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¸ "
                f"'{settings.STORAGE_COLLECTION_NAME}' Ð² '{settings.STORAGE_CHROMA_PATH}'"
            )
        except Exception as e:
            logger.exception(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ChromaVectorStore: {e}")
            raise

    async def asimilarity_search(self, query: str, with_score: bool, k: int = 3):
        """
        ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð² Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Chroma.

        Args:
            query (str): Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°
            with_score (bool): Ð’ÐºÐ»ÑŽÑ‡Ð°Ñ‚ÑŒ Ð»Ð¸ Ð¾Ñ†ÐµÐ½ÐºÑƒ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚Ð¸ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
            k (int): ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼Ñ‹Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²

        Returns:
            list: Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð², Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ Ñ Ð¾Ñ†ÐµÐ½ÐºÐ°Ð¼Ð¸ ÐµÑÐ»Ð¸ with_score=True

        Raises:
            RuntimeError: Ð•ÑÐ»Ð¸ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾
        """
        if not self._store:
            raise RuntimeError("ChromaVectorStore is not initialized.")
        logger.info(f"ðŸ” ÐŸÐ¾Ð¸ÑÐº Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð¿Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ: Â«{query}Â», top_k={k}")
        try:
            if with_score:
                # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð°ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸
                results = await self._store.asimilarity_search_with_score(
                    query=query, k=k
                )
            else:
                # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ð¹ Ð°ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´
                results = await self._store.asimilarity_search(query=query, k=k)
            logger.debug(f"ðŸ“„ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(results)} Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð².")
            return results
        except Exception as e:
            logger.exception(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð¸ÑÐºÐµ: {e}")
            raise

    async def close(self):
        """
        ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð»Ñ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ñ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ Ñ Ð±Ð°Ð·Ð¾Ð¹ Ð´Ð°Ð½Ð½Ñ‹Ñ… Chroma.
        Ð’ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ Ñ€ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Chroma Ð½Ðµ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ ÑÐ²Ð½Ð¾Ð³Ð¾ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ñ,
        Ð½Ð¾ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½ Ð´Ð»Ñ Ð¿Ð¾Ð»Ð½Ð¾Ñ‚Ñ‹ API Ð¸ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ñ… Ð±ÑƒÐ´ÑƒÑ‰Ð¸Ñ… Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹.
        """
        logger.info("ðŸ”Œ ÐžÑ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ ChromaVectorStore...")
        # ÐŸÐ¾ÐºÐ° Chroma Ð½Ðµ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ ÑÐ²Ð½Ð¾Ð³Ð¾ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ñ, Ð½Ð¾ Ð² Ð±ÑƒÐ´ÑƒÑ‰ÐµÐ¼ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿Ð¾Ð½Ð°Ð´Ð¾Ð±Ð¸Ñ‚ÑŒÑÑ
        # self._store.close() Ð¸Ð»Ð¸ Ð¿Ð¾Ð´Ð¾Ð±Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´
        pass

    async def load_documents_to_chroma(self, directory_path: str):
        """
        Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð¸Ð· ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ð¾Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ Ð² ChromaDB.
        """
        if not self.embeddings:
            raise RuntimeError("Embeddings not initialized. Call init() first.")

        logger.info(f"ðŸ“š Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð¸Ð· Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸: {directory_path}")
        documents = self._get_documents_from_directory(directory_path)

        if not documents:
            logger.warning("ðŸ¤· Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹.")
            return

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=settings.CHROMA_CHUNK_SIZE,
            chunk_overlap=settings.CHROMA_CHUNK_OVERLAP,
            length_function=len,
            is_separator_regex=False,
        )

        texts = text_splitter.split_documents(documents)
        logger.info(f"âœ‚ï¸ Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¾ Ð½Ð° {len(texts)} Ñ‡Ð°Ð½ÐºÐ¾Ð².")

        await self.add_documents(texts)

    async def add_documents(self, documents: list):
        """
        Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð² ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸ÑŽ ChromaDB.
        """
        if not self._store:
            raise RuntimeError(
                "ChromaVectorStore is not initialized. Call init() first."
            )
        if not self.embeddings:
            raise RuntimeError("Embeddings not initialized. Call init() first.")

        logger.info(f"âž• Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ {len(documents)} Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð² ChromaDB...")
        try:
            self._store.add_documents(documents)
            # Removed: self._store.persist() - no longer needed in ChromaDB 0.4.x and later
            logger.success("âœ… Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ñ‹ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² ChromaDB.")
        except Exception as e:
            logger.exception(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ð¸ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð² ChromaDB: {e}")
            raise

    def _get_documents_from_directory(self, directory_path: str):
        """
        Ð’ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ JSON-Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸Ð· Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸.
        """
        documents = []
        for filename in os.listdir(directory_path):
            if filename.endswith(".json"):
                filepath = os.path.join(directory_path, filename)
                try:
                    with open(filepath, "r", encoding="utf-8") as f:
                        data = json.load(f)
                        # ÐŸÑ€ÐµÐ´Ð¿Ð¾Ð»Ð°Ð³Ð°ÐµÐ¼, Ñ‡Ñ‚Ð¾ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ JSON-Ñ„Ð°Ð¹Ð» ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð¾Ð´Ð¸Ð½ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚
                        # Ñ Ð¿Ð¾Ð»ÑÐ¼Ð¸ 'page_content' Ð¸ 'metadata'
                        if "page_content" in data and "metadata" in data:
                            from langchain_core.documents import Document

                            documents.append(
                                Document(
                                    page_content=data["page_content"],
                                    metadata=data["metadata"],
                                )
                            )
                        else:
                            logger.warning(
                                f"âš ï¸ Ð¤Ð°Ð¹Ð» {filename} Ð½Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ 'page_content' Ð¸Ð»Ð¸ 'metadata'. ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼."
                            )
                except json.JSONDecodeError as e:
                    logger.error(
                        f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ JSON Ð² Ñ„Ð°Ð¹Ð»Ðµ {filename}: {e}"
                    )
                except Exception as e:
                    logger.error(
                        f"âŒ ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ‡Ñ‚ÐµÐ½Ð¸Ð¸ Ñ„Ð°Ð¹Ð»Ð° {filename}: {e}"
                    )
        return documents

    def get_all_document_ids(self) -> set[str]:
        """
        Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾ Ð²ÑÐµÑ… ID Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð², Ñ…Ñ€Ð°Ð½ÑÑ‰Ð¸Ñ…ÑÑ Ð² ChromaDB.
        """
        if not self._store:
            raise RuntimeError("ChromaVectorStore is not initialized.")
        try:
            # ChromaDB Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ ID Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð² ÑÐ²Ð¾ÐµÐ¹ ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¸. ÐœÑ‹ Ð¼Ð¾Ð¶ÐµÐ¼ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¸Ñ… Ñ‡ÐµÑ€ÐµÐ· _collection.get()
            # Ñ include=['metadatas'] Ð¸Ð»Ð¸ include=['documents'] Ð¸ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ ID.
            # Ð‘Ð¾Ð»ÐµÐµ Ð¿Ñ€ÑÐ¼Ð¾Ð¹ ÑÐ¿Ð¾ÑÐ¾Ð± - Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð²ÑÐµ ID Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ, ÐµÑÐ»Ð¸ API ÑÑ‚Ð¾ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚.
            # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ Ð¿Ñ€ÑÐ¼Ð¾Ð³Ð¾ Ð¼ÐµÑ‚Ð¾Ð´Ð°, Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð²ÑÐµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð¸ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ Ð¸Ñ… ID.
            # ÐŸÑ€ÐµÐ´Ð¿Ð¾Ð»Ð°Ð³Ð°ÐµÐ¼, Ñ‡Ñ‚Ð¾ ID Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹ Ð² Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð»Ð¸ ÐºÐ°Ðº Ñ‡Ð°ÑÑ‚ÑŒ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼Ð¾Ð³Ð¾ Ð¾Ð±ÑŠÐµÐºÑ‚Ð°.
            # Ð’ Langchain Chroma, ID Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ ÑÐ²Ð»ÑÑŽÑ‚ÑÑ Ñ‡Ð°ÑÑ‚ÑŒÑŽ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼Ñ‹Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
            # Ð¿Ñ€Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ Ð¸Ð»Ð¸ Ð¼Ð¾Ð³ÑƒÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ñ‹ Ñ‡ÐµÑ€ÐµÐ· Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ð¹ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ðº ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¸.
            # Ð”Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð²ÑÐµÑ… ID, Ð¼Ñ‹ Ð¼Ð¾Ð¶ÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð²ÑÐµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð¸ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ Ð¸Ñ… ID.
            # Ð­Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð½ÐµÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ Ð´Ð»Ñ Ð¾Ñ‡ÐµÐ½ÑŒ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¹.
            # Ð‘Ð¾Ð»ÐµÐµ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ ÑÐ¿Ð¾ÑÐ¾Ð± - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ _collection.get(ids=None, where=None, limit=None,
            # offset=None, include=[]) Ð¸ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ 'ids'.

            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð²ÑÐµ ID Ð¸Ð· ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¸ Chroma
            # Ð’Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ: ÑÑ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ð¾ Ð´Ð»Ñ Ð¾Ñ‡ÐµÐ½ÑŒ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¹
            all_ids = self._store._collection.get(
                ids=None, where=None, limit=None, offset=None, include=[]
            )["ids"]
            logger.info(f"ðŸ“Š ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¾ {len(all_ids)} ID Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð¸Ð· ChromaDB.")
            return set(all_ids)
        except Exception as e:
            logger.exception(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ð²ÑÐµÑ… ID Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð¸Ð· ChromaDB: {e}"
            )
            raise

    def get_all_source_filenames(self) -> set[str]:
        """
        Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾ Ð¸Ð¼ÐµÐ½ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð²ÑÐµÑ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð², Ñ…Ñ€Ð°Ð½ÑÑ‰Ð¸Ñ…ÑÑ Ð² ChromaDB.
        Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ 'source_file' Ð¸Ð· Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð².
        """
        if not self._store:
            raise RuntimeError("ChromaVectorStore is not initialized.")
        try:
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð²ÑÐµ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¸ Chroma
            all_metadatas = self._store._collection.get(include=["metadatas"])[
                "metadatas"
            ]
            source_files = set()

            # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¸Ð¼ÐµÐ½Ð° Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸Ð· Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ…
            for metadata in all_metadatas:
                if metadata and "source_file" in metadata:
                    source_files.add(metadata["source_file"])

            logger.info(
                f"ðŸ“Š ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¾ {len(source_files)} Ð¸Ð¼ÐµÐ½ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸Ð· Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ… ChromaDB."
            )
            return source_files
        except Exception as e:
            logger.exception(
                f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ð¸Ð¼ÐµÐ½ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸Ð· ChromaDB: {e}"
            )
            raise


# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¸Ð½ÑÑ‚Ð°Ð½Ñ
chroma_vectorstore = ChromaVectorStore()


# Ð—Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÑŒ
def get_vectorstore() -> ChromaVectorStore:
    return chroma_vectorstore
